{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTool\u001b[49m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle_missing_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mhandle_missing_values),\n\u001b[1;32m      2\u001b[0m Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mscale_features),\n\u001b[1;32m      3\u001b[0m Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode_categorical_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mencode_categorical_features),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tool' is not defined"
     ]
    }
   ],
   "source": [
    "    Tool(name=\"handle_missing_values\", func=handle_missing_values),\n",
    "    Tool(name=\"scale_features\", func=scale_features),\n",
    "    Tool(name=\"encode_categorical_features\", func=encode_categorical_features),\n",
    "    Tool(name=\"apply_pca\", func=apply_pca),\n",
    "    Tool(name=\"select_k_best_features\", func=select_k_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, strategy='mean'):\n",
    "    \"\"\"Handle missing values in the dataset.\"\"\"\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    imputed_df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "    return imputed_df\n",
    "\n",
    "def scale_features(df):\n",
    "    \"\"\"Scale numerical features using StandardScaler.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    return scaled_df\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    \"\"\"One-hot encode categorical features.\"\"\"\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_df = pd.DataFrame(encoder.fit_transform(df.select_dtypes(include=['object', 'category'])))\n",
    "    encoded_df.columns = encoder.get_feature_names_out(df.select_dtypes(include=['object', 'category']).columns)\n",
    "    df = df.drop(columns=df.select_dtypes(include=['object', 'category']).columns)\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    return df\n",
    "\n",
    "def apply_pca(df, n_components=2):\n",
    "    \"\"\"Apply Principal Component Analysis to reduce dimensionality.\"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_df = pd.DataFrame(pca.fit_transform(df), columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "    return pca_df\n",
    "\n",
    "def select_k_best_features(df, target, k=10):\n",
    "    \"\"\"Select the top k best features.\"\"\"\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    selected_df = selector.fit_transform(df, target)\n",
    "    selected_columns = df.columns[selector.get_support()]\n",
    "    return pd.DataFrame(selected_df, columns=selected_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
