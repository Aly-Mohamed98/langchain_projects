{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def handle_missing_values(df_str):\n",
    "    \"\"\"Handle missing values in the dataset based on df type.\"\"\"\n",
    "    data = globals()[df_str.split('\\n')[0]]\n",
    "    # print(\"The df type that enters the functions: \" + str(type(df)))\n",
    "    # data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lanchain_1/titanic.csv')\n",
    "    # df = pd.from_dict(data)\n",
    "    # print(df)\n",
    "    # df = convert_dict_to_DataFrame(df)\n",
    "    # print(\"The df that enters the functions: \" + df)\n",
    "    #print(df.head)\n",
    "    try:\n",
    "\n",
    "        # Separate numeric and categorical columns\n",
    "        numeric_cols = data.select_dtypes(include=['number']).columns\n",
    "        categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "        # Handle missing values for numeric columns\n",
    "        if numeric_cols.size > 0:\n",
    "            numeric_imputer = SimpleImputer(strategy='mean')\n",
    "            data[numeric_cols] = numeric_imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "        # Handle missing values for categorical columns\n",
    "        if categorical_cols.size > 0:\n",
    "            categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            data[categorical_cols] = categorical_imputer.fit_transform(data[categorical_cols])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in handle_missing_values: {e}\")\n",
    "    globals()[df_str.split('\\n')[0]] = data\n",
    "    data.to_csv('transformed_df.csv', index=False)\n",
    "    return data\n",
    "    # return \"Handled missing values in numerical columns: \" + str(numeric_cols) + \" and in categorical columns: \" + str(categorical_cols)\n",
    "\n",
    "@tool\n",
    "def encode_categorical_features(df_str):\n",
    "    \"\"\"Encode categorical features with one-hot encoding or label encoding based on the number of unique categories.\"\"\"\n",
    "    data = globals()[df_str.split('\\n')[0]]\n",
    "    max_categories = 10\n",
    "    all_encoded_cols = \"\"\n",
    "    all_labeled_cols = \"\"\n",
    "    try:\n",
    "        # Ensure the DataFrame contains categorical columns\n",
    "        categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "        if categorical_cols.size > 0:\n",
    "            for col in categorical_cols:\n",
    "                num_unique = data[col].nunique()\n",
    "\n",
    "                # Apply Label Encoding if the number of unique categories is too high\n",
    "                if num_unique > max_categories:\n",
    "                    print(f\"Applying Label Encoding to '{col}' with {num_unique} unique categories.\")\n",
    "                    label_encoder = LabelEncoder()\n",
    "                    data[col] = label_encoder.fit_transform(data[col])\n",
    "                    all_labeled_cols = all_labeled_cols + \" \" + col\n",
    "\n",
    "                else:\n",
    "                    print(f\"Applying One-Hot Encoding to '{col}' with {num_unique} unique categories.\")\n",
    "                    # Apply One-Hot Encoding for columns with a manageable number of categories\n",
    "                    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "                    encoded_array = encoder.fit_transform(data[[col]])\n",
    "                    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out([col]))\n",
    "                    data = data.drop(columns=[col])\n",
    "                    data = pd.concat([data, encoded_df], axis=1)\n",
    "                    all_encoded_cols = all_encoded_cols + \" \" + col\n",
    "        else:\n",
    "            print(\"No categorical columns to encode.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in encode_categorical_features: {e}\")\n",
    "\n",
    "    globals()[df_str.split('\\n')[0]] = data\n",
    "    data.to_csv('transformed_df.csv', index=False)\n",
    "    return data\n",
    "    # return \"done encoding\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def scale_features(df_str):\n",
    "    \"\"\"Scale numerical features using StandardScaler.\"\"\"\n",
    "    # df = convert_dict_to_DataFrame(df)\n",
    "    data = globals()[df_str.split('\\n')[0]]\n",
    "    try:\n",
    "        # Ensure the DataFrame contains numerical df\n",
    "        numeric_cols = data.select_dtypes(include=['number']).columns\n",
    "        if numeric_cols.size > 0:\n",
    "            scaler = StandardScaler()\n",
    "            data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "        else:\n",
    "            print(\"No numerical columns to scale.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scale_features: {e}\")\n",
    "    # data.to_csv('transformed_df.csv', index=False)\n",
    "    globals()[df_str.split('\\n')[0]] = data\n",
    "    data.to_csv('transformed_df.csv', index=False)\n",
    "    return data\n",
    "    # return \"Done scaling numerical features.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the part of the code that will read the csv file and convert it to a dictionary where the key is the name of the column and the value is the datatype of each column\n",
    "#This will be used to be fed to the prompt of the agent\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df_types = str(df.dtypes).split('\\n')\n",
    "df_types = [i.split('     ') for i in df_types]\n",
    "# Initialize an empty dictionary\n",
    "column_types = {}\n",
    "\n",
    "# Process each row in the 2D array\n",
    "for row in df_types:\n",
    "    # The column name is the first element\n",
    "    column_name = row[0].strip()\n",
    "\n",
    "    # The data type is the last non-empty element\n",
    "    data_type = None\n",
    "    for item in reversed(row[1:]):\n",
    "        if item.strip():\n",
    "            data_type = item.strip()\n",
    "            break\n",
    "\n",
    "    # Only add to dictionary if we have both column name and data type\n",
    "    if column_name and data_type:\n",
    "        column_types[column_name] = data_type\n",
    "\n",
    "# Remove any unwanted entries like 'dtype: object'\n",
    "column_types.pop('dtype: object', None)\n",
    "\n",
    "# Print the result\n",
    "print(column_types)\n",
    "column_types_string = str(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an array of the tools that will be used in the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"handle_missing_values\",\n",
    "        func=handle_missing_values,\n",
    "        description=\"This is a tool that can help handling missing values in a dataset. It can only take input 'df'. It imputes the numerical columns with mean values and the categorical values with most frequent\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"scale_features\",\n",
    "        func=scale_features,\n",
    "        description=\"Scale numerical features using StandardScaler to standardize features to have zero mean and unit variance. It can only take input 'df'.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"encode_categorical_features\",\n",
    "        func=encode_categorical_features,\n",
    "        description=\"One-hot encode categorical features, converting categorical values into binary vectors. It can only take input 'df'.\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the python Repl tool to the tools array with the dataframe as a global variable in that tool\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "\n",
    "tools = [PythonAstREPLTool(globals={\"df\": df})] + tools"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
